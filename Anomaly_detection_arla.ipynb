{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curiouscat7/Anomaly-detection/blob/main/Anomaly_detection_arla.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c553bd17",
      "metadata": {
        "id": "c553bd17"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee8aa98",
      "metadata": {
        "id": "5ee8aa98"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"arla_keyword_table.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4d105f7",
      "metadata": {
        "id": "f4d105f7",
        "outputId": "b33eafca-3962-409d-85b5-af55e144c4d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outliers:\n",
            "       PRODUCT_TITLE  Keyword Type                           Keyword  Outlier\n",
            "0                 13             2                      white cheese       -1\n",
            "39                13             2             white cheese less fat       -1\n",
            "71                13             1                       feta cheese       -1\n",
            "76                13             1                     romano cheese       -1\n",
            "77                13             1                  roquefort cheese       -1\n",
            "...              ...           ...                               ...      ...\n",
            "23279             80             1            yoplait protein yogurt       -1\n",
            "23288             80             1  yocrunch fitness friendly yogurt       -1\n",
            "23368             78             1              yoplait pouch yogurt       -1\n",
            "23468             70             1              yoplait mango yogurt       -1\n",
            "23477             70             1             yocrunch mango yogurt       -1\n",
            "\n",
            "[1175 rows x 4 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/k6/2syb2mv54wn0mgvxrj8n8ltm0000gp/T/ipykernel_12561/1038981130.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  outliers_df['Keyword'] = label_encoder.inverse_transform(outliers_df['Keyword'])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "# Encode categorical columns ('ASIN' and 'Keyword Type') into numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "df['PRODUCT_TITLE'] = label_encoder.fit_transform(df['PRODUCT_TITLE'])\n",
        "df['Keyword Type'] = label_encoder.fit_transform(df['Keyword Type'])\n",
        "\n",
        "# Encode the 'Keyword' column\n",
        "df['Keyword'] = label_encoder.fit_transform(df['Keyword'])\n",
        "\n",
        "# Select relevant columns for outlier detection\n",
        "X = df[['PRODUCT_TITLE', 'Keyword Type', 'Keyword']]\n",
        "\n",
        "# Initialize the Isolation Forest model\n",
        "# You can adjust hyperparameters like 'n_estimators', 'contamination', etc.\n",
        "clf = IsolationForest(contamination=0.05, random_state=42)\n",
        "\n",
        "# Fit the model to your data and predict outliers\n",
        "df['Outlier'] = clf.fit_predict(X)\n",
        "\n",
        "# Filter the DataFrame to include only outliers (Outlier == -1)\n",
        "outliers_df = df[df['Outlier'] == -1]\n",
        "\n",
        "# Decode the 'Keyword' column to its original values if needed\n",
        "outliers_df['Keyword'] = label_encoder.inverse_transform(outliers_df['Keyword'])\n",
        "\n",
        "# Save the outliers to a CSV file\n",
        "outliers_df.to_csv('outliers_arla.csv', index=False)\n",
        "\n",
        "# Print or inspect the outliers if needed\n",
        "print(\"Outliers:\")\n",
        "print(outliers_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "477a7e9d",
      "metadata": {
        "id": "477a7e9d",
        "outputId": "af0d89ea-3cb8-4d3d-9793-87748cc0009f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: boto3 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.28)\n",
            "Requirement already satisfied: requests in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (2.29.0)\n",
            "Requirement already satisfied: tqdm in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
            "Collecting sentencepiece (from transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp311-cp311-macosx_10_9_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from boto3->transformers) (1.27.59)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from boto3->transformers) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from boto3->transformers) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: six in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: click in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from sacremoses->transformers) (8.0.4)\n",
            "Requirement already satisfied: joblib in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from sacremoses->transformers) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from botocore<1.28.0,>=1.27.28->boto3->transformers) (2.8.2)\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e8a7f0",
      "metadata": {
        "id": "82e8a7f0",
        "outputId": "acd68abe-c477-47f9-e765-5805b46db3e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (2.1.1)\n",
            "Collecting transformers\n",
            "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/e1/9d/4d9fe5c3b820db10773392ac5f4a0c8dab668f70b245ce2ce09785166128/transformers-4.33.0-py3-none-any.whl.metadata\n",
            "  Using cached transformers-4.33.0-py3-none-any.whl.metadata (119 kB)\n",
            "Requirement already satisfied: filelock in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Obtaining dependency information for huggingface-hub<1.0,>=0.15.1 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
            "  Using cached huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (2.29.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Using cached tokenizers-0.13.3-cp311-cp311-macosx_10_11_universal2.whl (4.0 MB)\n",
            "Collecting safetensors>=0.3.1 (from transformers)\n",
            "  Using cached safetensors-0.3.3.tar.gz (35 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n",
            "Using cached transformers-4.33.0-py3-none-any.whl (7.6 MB)\n",
            "Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "Building wheels for collected packages: safetensors\n",
            "  Building wheel for safetensors (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for safetensors: filename=safetensors-0.3.3-cp311-cp311-macosx_13_0_x86_64.whl size=416890 sha256=5afb475b568ae96284d9dea358b522d0084f6b54a0b1f341fce150ec43714dd0\n",
            "  Stored in directory: /Users/samanwitamukherjee/Library/Caches/pip/wheels/ed/6c/85/25ad49fce337517b8202f204c0843f5208c3108128ceca94e3\n",
            "Successfully built safetensors\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 2.1.1\n",
            "    Uninstalling transformers-2.1.1:\n",
            "      Successfully uninstalled transformers-2.1.1\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53d11c88",
      "metadata": {
        "id": "53d11c88",
        "outputId": "ef630561-652e-40c9-c166-ed1d9ec2bba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.0.1-cp311-none-macosx_10_9_x86_64.whl (143.1 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from torch) (2.8.4)\n",
            "Requirement already satisfied: jinja2 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.2.1)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-2.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a54403f7",
      "metadata": {
        "id": "a54403f7",
        "outputId": "f9de50c7-bdc4-4d3f-b621-1d6ed9c34b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.2.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        " pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9883e07a",
      "metadata": {
        "id": "9883e07a",
        "outputId": "b7c5a704-118d-439c-95c1-69f7e5dd48f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anomalies saved to 'anomalies.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Assuming you have loaded your DataFrame 'df' with your data\n",
        "\n",
        "# Encode categorical columns (product_title and keyword_type)\n",
        "label_encoders = {}\n",
        "for column in [\"PRODUCT_TITLE\", \"Keyword Type\"]:\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Define BERT tokenizer and model\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "# Encode the keywords using BERT embeddings\n",
        "keyword_embeddings = []\n",
        "\n",
        "max_length = 128  # Define your desired maximum length\n",
        "\n",
        "for keyword in df['Keyword']:\n",
        "    # Manually truncate the input sequence to the desired maximum length\n",
        "    keyword = keyword[:max_length]\n",
        "    inputs = tokenizer.encode_plus(keyword, add_special_tokens=True, padding=True, max_length=max_length, truncation=True, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        hidden_states = outputs.last_hidden_state\n",
        "    embeddings = hidden_states.mean(dim=1).squeeze().numpy()  # Mean pooling of BERT embeddings\n",
        "    keyword_embeddings.append(embeddings)\n",
        "\n",
        "X = np.hstack([df[[\"PRODUCT_TITLE\", \"Keyword Type\"]].values, np.vstack(keyword_embeddings)])\n",
        "\n",
        "# Train a suitable anomaly detection model (e.g., Isolation Forest, One-Class SVM)\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "clf = IsolationForest(contamination=0.05, random_state=42)  # Adjust the contamination parameter as needed\n",
        "clf.fit(X)\n",
        "\n",
        "# Predict anomalies (outliers)\n",
        "df[\"anomaly_score\"] = clf.decision_function(X)\n",
        "df[\"is_anomaly\"] = clf.predict(X)\n",
        "\n",
        "# Save anomalies to a CSV file\n",
        "anomalies = df[df[\"is_anomaly\"] == -1]\n",
        "anomalies.to_csv(\"anomalies.csv\", index=False)\n",
        "\n",
        "print(\"Anomalies saved to 'anomalies.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "017e3bf7",
      "metadata": {
        "id": "017e3bf7",
        "outputId": "a24eec19-1f11-427f-9f45-894ea2bd0646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (4.33.0)\n",
            "Requirement already satisfied: filelock in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (2.29.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/samanwitamukherjee/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2900f831",
      "metadata": {
        "id": "2900f831",
        "outputId": "3020fdab-64f8-4de2-ba69-6b830814386d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anomalies saved to 'anomalies_SVM.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.svm import OneClassSVM  # Import the One-Class SVM module\n",
        "\n",
        "# Assuming you have loaded your DataFrame 'df' with your data\n",
        "\n",
        "# Encode categorical columns (product_title and keyword_type)\n",
        "label_encoders = {}\n",
        "for column in [\"PRODUCT_TITLE\", \"Keyword Type\"]:\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Define BERT tokenizer and model\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "# Encode the keywords using BERT embeddings\n",
        "keyword_embeddings = []\n",
        "\n",
        "max_length = 128  # Define your desired maximum length\n",
        "\n",
        "for keyword in df['Keyword']:\n",
        "    # Manually truncate the input sequence to the desired maximum length\n",
        "    keyword = keyword[:max_length]\n",
        "    inputs = tokenizer.encode_plus(keyword, add_special_tokens=True, padding=True, max_length=max_length, truncation=True, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        hidden_states = outputs.last_hidden_state\n",
        "    embeddings = hidden_states.mean(dim=1).squeeze().numpy()  # Mean pooling of BERT embeddings\n",
        "    keyword_embeddings.append(embeddings)\n",
        "\n",
        "X = np.hstack([df[[\"PRODUCT_TITLE\", \"Keyword Type\"]].values, np.vstack(keyword_embeddings)])\n",
        "\n",
        "# Train a suitable anomaly detection model (e.g., One-Class SVM)\n",
        "clf = OneClassSVM(nu=0.05)  # Adjust the nu parameter as needed\n",
        "clf.fit(X)\n",
        "\n",
        "# Predict anomalies (outliers)\n",
        "df[\"anomaly_score\"] = clf.decision_function(X)\n",
        "df[\"is_anomaly\"] = clf.predict(X)\n",
        "\n",
        "# Save anomalies to a CSV file\n",
        "anomalies = df[df[\"is_anomaly\"] == -1]\n",
        "anomalies.to_csv(\"anomalies_SVM.csv\", index=False)\n",
        "\n",
        "print(\"Anomalies saved to 'anomalies_SVM.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16329081",
      "metadata": {
        "id": "16329081"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}